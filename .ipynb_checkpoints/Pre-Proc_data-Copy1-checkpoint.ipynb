{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# this is for loading the data\n",
    "def load_fall_X(file_name):\n",
    "    temp = np.memmap(file_name, dtype='float32', mode='r')\n",
    "    X = np.reshape(temp, [-1, 256, 6])\n",
    "    return X\n",
    "\n",
    "# this is for loading the labels (one-hot encoding: [1, 0, 0]-->nonfall, [0, 1, 0]-->pre-impact fall, [0, 0, 1]-->fall\t\n",
    "def load_fall_y(file_name):\n",
    "    temp = np.memmap(file_name, dtype='int8', mode='r')\n",
    "    y= np.reshape(temp, [-1, 3])\n",
    "    return y\n",
    "\n",
    "def dset_fpath(fname):\n",
    "    return os.path.abspath(\"data/pre-processed_dataset/%s\" % fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  = {'X': {}, 'y': {}}\n",
    "train = {'X': {}, 'y': {}}\n",
    "for i in range(5):\n",
    "    test['X'][i] = load_fall_X(dset_fpath(\"test_x_%i\" % i))\n",
    "    test['y'][i] = load_fall_y(dset_fpath(\"test_y_%i\" % i))\n",
    "    train['X'][i] = load_fall_X(dset_fpath(\"train_x_%i\" % i))\n",
    "    train['y'][i] = load_fall_y(dset_fpath(\"train_y_%i\" % i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 0\n",
      " X train shape: (75025, 256, 6)\n",
      " y train shape: (75025, 3)\n",
      " X test shape:  (19064, 256, 6)\n",
      " y test shape:  (19064, 3)\n",
      "Set 1\n",
      " X train shape: (73347, 256, 6)\n",
      " y train shape: (73347, 3)\n",
      " X test shape:  (20742, 256, 6)\n",
      " y test shape:  (20742, 3)\n",
      "Set 2\n",
      " X train shape: (73534, 256, 6)\n",
      " y train shape: (73534, 3)\n",
      " X test shape:  (20555, 256, 6)\n",
      " y test shape:  (20555, 3)\n",
      "Set 3\n",
      " X train shape: (77296, 256, 6)\n",
      " y train shape: (77296, 3)\n",
      " X test shape:  (16793, 256, 6)\n",
      " y test shape:  (16793, 3)\n",
      "Set 4\n",
      " X train shape: (77154, 256, 6)\n",
      " y train shape: (77154, 3)\n",
      " X test shape:  (16935, 256, 6)\n",
      " y test shape:  (16935, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Set\", i)\n",
    "    print(\" X train shape:\", train['X'][i].shape)\n",
    "    print(\" y train shape:\", train['y'][i].shape)\n",
    "    print(\" X test shape: \", test['X'][i].shape)\n",
    "    print(\" y test shape: \", test['y'][i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 254, 64)           1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 254, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 127, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 125, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 125, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 60, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 60, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 512)               983552    \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 1,011,779\n",
      "Trainable params: 1,011,395\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_timesteps = 256\n",
    "n_features = 6\n",
    "n_outputs = 3\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# First layer\n",
    "model.add(layers.Conv1D(kernel_size=3, \n",
    "                        filters=64, \n",
    "                        activation='relu', \n",
    "                        input_shape=(n_timesteps, n_features)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "# Second layer\n",
    "model.add(layers.Conv1D(kernel_size = 3, \n",
    "                        filters = 64, \n",
    "                        activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "\n",
    "# Third layer\n",
    "model.add(layers.Conv1D(kernel_size = 3, \n",
    "                        filters = 64, \n",
    "                        activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512))\n",
    "model.add(layers.Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "print(model.summary())\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1173/1173 [==============================] - 29s 25ms/step - loss: 0.2045 - accuracy: 0.9681\n",
      "Epoch 2/30\n",
      "1173/1173 [==============================] - 29s 25ms/step - loss: 0.0701 - accuracy: 0.9818\n",
      "Epoch 3/30\n",
      "1173/1173 [==============================] - 30s 25ms/step - loss: 0.0619 - accuracy: 0.9825\n",
      "Epoch 4/30\n",
      "1173/1173 [==============================] - 29s 25ms/step - loss: 0.0602 - accuracy: 0.9829\n",
      "Epoch 5/30\n",
      "1173/1173 [==============================] - 30s 25ms/step - loss: 0.0564 - accuracy: 0.9838\n",
      "Epoch 6/30\n",
      "1173/1173 [==============================] - 30s 25ms/step - loss: 0.0518 - accuracy: 0.9846\n",
      "Epoch 7/30\n",
      "1173/1173 [==============================] - 30s 25ms/step - loss: 0.0485 - accuracy: 0.9855\n",
      "Epoch 8/30\n",
      "1173/1173 [==============================] - 29s 25ms/step - loss: 0.0442 - accuracy: 0.9863\n",
      "Epoch 9/30\n",
      "1173/1173 [==============================] - 30s 25ms/step - loss: 0.0422 - accuracy: 0.9871\n",
      "Epoch 10/30\n",
      "1173/1173 [==============================] - 30s 25ms/step - loss: 0.0393 - accuracy: 0.9879\n",
      "Epoch 11/30\n",
      "1173/1173 [==============================] - 30s 25ms/step - loss: 0.0374 - accuracy: 0.9881\n",
      "Epoch 12/30\n",
      "1173/1173 [==============================] - 30s 25ms/step - loss: 0.0347 - accuracy: 0.9891\n",
      "Epoch 13/30\n",
      "1173/1173 [==============================] - 30s 25ms/step - loss: 0.0341 - accuracy: 0.9898\n",
      "Epoch 14/30\n",
      "1173/1173 [==============================] - 30s 25ms/step - loss: 0.0302 - accuracy: 0.9907\n",
      "Epoch 15/30\n",
      "1173/1173 [==============================] - 30s 25ms/step - loss: 0.0303 - accuracy: 0.9904\n",
      "Epoch 16/30\n",
      "1173/1173 [==============================] - 30s 25ms/step - loss: 0.0277 - accuracy: 0.9907\n",
      "Epoch 17/30\n",
      "1173/1173 [==============================] - 30s 26ms/step - loss: 0.0277 - accuracy: 0.9911\n",
      "Epoch 18/30\n",
      "1173/1173 [==============================] - 30s 25ms/step - loss: 0.0266 - accuracy: 0.9916\n",
      "Epoch 19/30\n",
      "1173/1173 [==============================] - 30s 26ms/step - loss: 0.0237 - accuracy: 0.9923\n",
      "Epoch 20/30\n",
      "1173/1173 [==============================] - 31s 26ms/step - loss: 0.0236 - accuracy: 0.9924\n",
      "Epoch 21/30\n",
      "1173/1173 [==============================] - 30s 26ms/step - loss: 0.0217 - accuracy: 0.9929\n",
      "Epoch 22/30\n",
      "1173/1173 [==============================] - 29s 25ms/step - loss: 0.0242 - accuracy: 0.9922\n",
      "Epoch 23/30\n",
      "1173/1173 [==============================] - 30s 26ms/step - loss: 0.0201 - accuracy: 0.9935\n",
      "Epoch 24/30\n",
      "1173/1173 [==============================] - 30s 25ms/step - loss: 0.0184 - accuracy: 0.9937\n",
      "Epoch 25/30\n",
      "1173/1173 [==============================] - 30s 26ms/step - loss: 0.0220 - accuracy: 0.9931\n",
      "Epoch 26/30\n",
      " 189/1173 [===>..........................] - ETA: 25s - loss: 0.0151 - accuracy: 0.9945"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-2073bcc15169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i=0\n",
    "X_train, y_train = train['X'][i], train['y'][i]\n",
    "X_test, y_test = test['X'][i], test['y'][i]\n",
    "history = model.fit(X_train, y_train, epochs = 30, batch_size = 64 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/596 - 3s - loss: 1.0396 - accuracy: 0.8907\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-eaeb40ec4f7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99638081e-01, 1.72424217e-04, 1.89460741e-04],\n",
       "       [9.99643922e-01, 1.77643786e-04, 1.78348913e-04],\n",
       "       [9.99565184e-01, 2.29074765e-04, 2.05736666e-04],\n",
       "       ...,\n",
       "       [9.99863267e-01, 2.11951301e-05, 1.15517883e-04],\n",
       "       [9.99861479e-01, 2.17399720e-05, 1.16810275e-04],\n",
       "       [9.99861360e-01, 2.17430807e-05, 1.16936208e-04]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_max = np.argmax(y_pred, axis=1)\n",
    "y_test_max = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16981,     9,  1691],\n",
       "       [  233,     0,     0],\n",
       "       [  150,     0,     0]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "confusion_matrix(y_test_max, y_pred_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     no fall       0.98      0.91      0.94     18681\n",
      "    pre-fall       0.00      0.00      0.00       233\n",
      "        fall       0.00      0.00      0.00       150\n",
      "\n",
      "    accuracy                           0.89     19064\n",
      "   macro avg       0.33      0.30      0.31     19064\n",
      "weighted avg       0.96      0.89      0.92     19064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_max, y_pred_max, target_names=['no fall', 'pre-fall', 'fall']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity\n",
    "\\begin{align}\n",
    "\\text{Sensitivity} &= \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} \\\\\n",
    "\\text{Specificity} &= \\frac{\\text{TN}}{\\text{TN} + \\text{FP}} \\\\\n",
    "\\text{Accuracy} &= \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{FP} + \\text{TN} + \\text{FN}} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now for the hybrid model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 254, 64)           1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 254, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 127, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 125, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 125, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 60, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 60, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 512)               983552    \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 1,011,779\n",
      "Trainable params: 1,011,395\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_timesteps = 256\n",
    "n_features = 6\n",
    "n_outputs = 3\n",
    "\n",
    "TIME_PERIODS = n_timesteps\n",
    "num_sensors = n_features\n",
    "num_classes = n_outputs\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv1D(kernel_size=3, \n",
    "                        filters=64, \n",
    "                        activation='relu', \n",
    "                        input_shape=(TIME_PERIODS, num_sensors)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "\n",
    "model.add(layers.Conv1D(kernel_size = 3, \n",
    "                        filters = 64, \n",
    "                        activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "\n",
    "model.add(layers.Conv1D(kernel_size = 3, \n",
    "                        filters = 64, \n",
    "                        activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "\n",
    "# model.add(layers.Conv1D(kernel_size = 1, \n",
    "#                         filters = 1920, \n",
    "#                         activation='relu'))\n",
    "\n",
    "# model.add(layers.GlobalAveragePooling1D())\n",
    "# model.add(layers.MaxPooling1D(30))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# model.add(layers.Dense(1920))\n",
    "model.add(layers.Dense(512))\n",
    "\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "# model.add(layers.Flatten())\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "print(model.summary())\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
