{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# this is for loading the data\n",
    "def load_fall_X(file_name):\n",
    "    temp = np.memmap(file_name, dtype='float32', mode='r')\n",
    "    X = np.reshape(temp, [-1, 256, 6])\n",
    "    return X\n",
    "\n",
    "# this is for loading the labels (one-hot encoding: [1, 0, 0]-->nonfall, [0, 1, 0]-->pre-impact fall, [0, 0, 1]-->fall\t\n",
    "def load_fall_y(file_name):\n",
    "    temp = np.memmap(file_name, dtype='int8', mode='r')\n",
    "    y= np.reshape(temp, [-1, 3])\n",
    "    return y\n",
    "\n",
    "def dset_fpath(fname):\n",
    "    _fp = os.path.abspath('.')\n",
    "    _hp = \"wobblewatch\"\n",
    "    _fp = _fp.split(_hp)[0]\n",
    "    return os.path.abspath(\"%s/%s/data/sisfall/preproc/%s\" % (_fp, _hp, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  = {'X': {}, 'y': {}}\n",
    "train = {'X': {}, 'y': {}}\n",
    "for i in range(5):\n",
    "    test['X'][i] = load_fall_X(dset_fpath(\"test_x_%i\" % i))\n",
    "    test['y'][i] = load_fall_y(dset_fpath(\"test_y_%i\" % i))\n",
    "    train['X'][i] = load_fall_X(dset_fpath(\"train_x_%i\" % i))\n",
    "    train['y'][i] = load_fall_y(dset_fpath(\"train_y_%i\" % i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 0\n",
      " X train shape: (75025, 256, 6)\n",
      " y train shape: (75025, 3)\n",
      " X test shape:  (19064, 256, 6)\n",
      " y test shape:  (19064, 3)\n",
      "Set 1\n",
      " X train shape: (73347, 256, 6)\n",
      " y train shape: (73347, 3)\n",
      " X test shape:  (20742, 256, 6)\n",
      " y test shape:  (20742, 3)\n",
      "Set 2\n",
      " X train shape: (73534, 256, 6)\n",
      " y train shape: (73534, 3)\n",
      " X test shape:  (20555, 256, 6)\n",
      " y test shape:  (20555, 3)\n",
      "Set 3\n",
      " X train shape: (77296, 256, 6)\n",
      " y train shape: (77296, 3)\n",
      " X test shape:  (16793, 256, 6)\n",
      " y test shape:  (16793, 3)\n",
      "Set 4\n",
      " X train shape: (77154, 256, 6)\n",
      " y train shape: (77154, 3)\n",
      " X test shape:  (16935, 256, 6)\n",
      " y test shape:  (16935, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Set\", i)\n",
    "    print(\" X train shape:\", train['X'][i].shape)\n",
    "    print(\" y train shape:\", train['y'][i].shape)\n",
    "    print(\" X test shape: \", test['X'][i].shape)\n",
    "    print(\" y test shape: \", test['y'][i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['y'][0]\n",
    "print(y)\n",
    "y[y[:,0] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "setnum = 0\n",
    "\n",
    "\n",
    "col_start = {\"acc\": 0, \"rot\": 3}\n",
    "col = col_start['rot']\n",
    "X, y = train['X'][setnum], train['y'][setnum]\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape, y.shape)\n",
    "labeli = 1\n",
    "labelj = 1\n",
    "X_fpf, y_fpf = X[y[:,labeli] == labelj], y[y[:,labeli] == labelj]\n",
    "print(X_fpf.shape, y_fpf.shape)\n",
    "\n",
    "# for index in range(len(X_fpf)):\n",
    "for index in range(5):\n",
    "    _X = X[index]\n",
    "#     print(_X.shape)\n",
    "    plt.plot(_X[:,col])\n",
    "    plt.plot(_X[:,col+1])\n",
    "    plt.plot(_X[:,col+2])\n",
    "    plt.show()\n",
    "    \n",
    "X_fpf, y_fpf = X[y[:,0] == 0], y[y[:,0] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "from tensorflow_addons import losses \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_timesteps = 256\n",
    "n_features = 6\n",
    "n_outputs = 3\n",
    "\n",
    "def cnn_model():\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv1D(kernel_size=3, \n",
    "                            filters=64, \n",
    "                            activation='relu', \n",
    "                            input_shape=(n_timesteps, n_features)))\n",
    "\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(2))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Conv1D(kernel_size = 3, \n",
    "                            filters = 64, \n",
    "                            activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(2))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Conv1D(kernel_size = 3, \n",
    "                            filters = 64, \n",
    "                            activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(60))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # model.add(layers.Conv1D(kernel_size = 1, \n",
    "    #                         filters = 1920, \n",
    "    #                         activation='relu'))\n",
    "\n",
    "    # model.add(layers.GlobalAveragePooling1D())\n",
    "    model.add(layers.Dense(512))\n",
    "\n",
    "    model.add(layers.Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    opt = optimizers.Nadam(learning_rate=0.0005)\n",
    "    lss = losses.SigmoidFocalCrossEntropy()\n",
    "#     lss = losses.focal_loss()\n",
    "    model.compile(loss=lss, optimizer=opt, metrics=['accuracy'])    \n",
    "\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next I run the 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 254, 64)           1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 254, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 127, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 127, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 125, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 125, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 60, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 60, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1, 512)            33280     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1, 3)              1539      \n",
      "=================================================================\n",
      "Total params: 61,507\n",
      "Trainable params: 61,123\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "1173/1173 [==============================] - 43s 37ms/step - loss: 0.0713 - accuracy: 0.6642 - val_loss: 0.0725 - val_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "1173/1173 [==============================] - 43s 37ms/step - loss: 0.0498 - accuracy: 0.6653 - val_loss: 0.0395 - val_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "1173/1173 [==============================] - 43s 36ms/step - loss: 0.0390 - accuracy: 0.6656 - val_loss: 0.0305 - val_accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "1173/1173 [==============================] - 40s 34ms/step - loss: 0.0325 - accuracy: 0.6662 - val_loss: 0.0274 - val_accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "1173/1173 [==============================] - 41s 35ms/step - loss: 0.0298 - accuracy: 0.6664 - val_loss: 0.0350 - val_accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "1173/1173 [==============================] - 41s 35ms/step - loss: 0.0309 - accuracy: 0.6663 - val_loss: 0.0273 - val_accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "1173/1173 [==============================] - 41s 35ms/step - loss: 0.0286 - accuracy: 0.6666 - val_loss: 0.0279 - val_accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "1173/1173 [==============================] - 41s 35ms/step - loss: 0.0286 - accuracy: 0.6666 - val_loss: 0.0274 - val_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "1173/1173 [==============================] - 41s 35ms/step - loss: 0.0291 - accuracy: 0.6665 - val_loss: 0.0275 - val_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "1173/1173 [==============================] - 42s 36ms/step - loss: 0.0284 - accuracy: 0.6667 - val_loss: 0.0274 - val_accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "1173/1173 [==============================] - 42s 36ms/step - loss: 0.0282 - accuracy: 0.6667 - val_loss: 0.0275 - val_accuracy: 0.6667\n",
      "Epoch 12/20\n",
      "1173/1173 [==============================] - 43s 37ms/step - loss: 0.0283 - accuracy: 0.6667 - val_loss: 0.0283 - val_accuracy: 0.6667\n",
      "Epoch 13/20\n",
      "1173/1173 [==============================] - 41s 35ms/step - loss: 0.0282 - accuracy: 0.6667 - val_loss: 0.0277 - val_accuracy: 0.6667\n",
      "Epoch 14/20\n",
      "1173/1173 [==============================] - 41s 35ms/step - loss: 0.0282 - accuracy: 0.6667 - val_loss: 0.0275 - val_accuracy: 0.6667\n",
      "Epoch 15/20\n",
      "1173/1173 [==============================] - 44s 37ms/step - loss: 0.0281 - accuracy: 0.6667 - val_loss: 0.0272 - val_accuracy: 0.6667\n",
      "Epoch 16/20\n",
      "1173/1173 [==============================] - 43s 37ms/step - loss: 0.0281 - accuracy: 0.6667 - val_loss: 0.0285 - val_accuracy: 0.6667\n",
      "Epoch 17/20\n",
      "1173/1173 [==============================] - 43s 36ms/step - loss: 0.0281 - accuracy: 0.6667 - val_loss: 0.0277 - val_accuracy: 0.6667\n",
      "Epoch 18/20\n",
      "1173/1173 [==============================] - 43s 36ms/step - loss: 0.0281 - accuracy: 0.6667 - val_loss: 0.0274 - val_accuracy: 0.6667\n",
      "Epoch 19/20\n",
      "1173/1173 [==============================] - 44s 38ms/step - loss: 0.0280 - accuracy: 0.6667 - val_loss: 0.0273 - val_accuracy: 0.6667\n",
      "Epoch 20/20\n",
      "1173/1173 [==============================] - 44s 37ms/step - loss: 0.0280 - accuracy: 0.6667 - val_loss: 0.0272 - val_accuracy: 0.6667\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 254, 64)           1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 254, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 127, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 127, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 125, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 125, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 60, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 60, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1, 512)            33280     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1, 3)              1539      \n",
      "=================================================================\n",
      "Total params: 61,507\n",
      "Trainable params: 61,123\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "1147/1147 [==============================] - 43s 38ms/step - loss: 0.0788 - accuracy: 0.6642 - val_loss: 0.0657 - val_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "1147/1147 [==============================] - 43s 37ms/step - loss: 0.0509 - accuracy: 0.6654 - val_loss: 0.0383 - val_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "1147/1147 [==============================] - 42s 37ms/step - loss: 0.0391 - accuracy: 0.6655 - val_loss: 0.0364 - val_accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "1147/1147 [==============================] - 42s 36ms/step - loss: 0.0323 - accuracy: 0.6661 - val_loss: 0.0348 - val_accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "1147/1147 [==============================] - 43s 37ms/step - loss: 0.0322 - accuracy: 0.6661 - val_loss: 0.0290 - val_accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "1147/1147 [==============================] - 43s 37ms/step - loss: 0.0281 - accuracy: 0.6666 - val_loss: 0.0297 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "1147/1147 [==============================] - 43s 37ms/step - loss: 0.0282 - accuracy: 0.6666 - val_loss: 0.0289 - val_accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "1147/1147 [==============================] - 39s 34ms/step - loss: 0.0281 - accuracy: 0.6667 - val_loss: 0.0291 - val_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "1147/1147 [==============================] - 42s 37ms/step - loss: 0.0282 - accuracy: 0.6666 - val_loss: 0.0291 - val_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "1147/1147 [==============================] - 42s 36ms/step - loss: 0.0279 - accuracy: 0.6667 - val_loss: 0.0291 - val_accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "1147/1147 [==============================] - 42s 37ms/step - loss: 0.0278 - accuracy: 0.6667 - val_loss: 0.0290 - val_accuracy: 0.6667\n",
      "Epoch 12/20\n",
      "1147/1147 [==============================] - 41s 36ms/step - loss: 0.0278 - accuracy: 0.6667 - val_loss: 0.0291 - val_accuracy: 0.6667\n",
      "Epoch 13/20\n",
      "1147/1147 [==============================] - 41s 35ms/step - loss: 0.0277 - accuracy: 0.6667 - val_loss: 0.0292 - val_accuracy: 0.6667\n",
      "Epoch 14/20\n",
      "1147/1147 [==============================] - 42s 37ms/step - loss: 0.0275 - accuracy: 0.6667 - val_loss: 0.0291 - val_accuracy: 0.6667\n",
      "Epoch 15/20\n",
      "1147/1147 [==============================] - 42s 36ms/step - loss: 0.0276 - accuracy: 0.6667 - val_loss: 0.0292 - val_accuracy: 0.6667\n",
      "Epoch 16/20\n",
      "1147/1147 [==============================] - 40s 35ms/step - loss: 0.0275 - accuracy: 0.6667 - val_loss: 0.0291 - val_accuracy: 0.6667\n",
      "Epoch 17/20\n",
      "1147/1147 [==============================] - 42s 36ms/step - loss: 0.0275 - accuracy: 0.6667 - val_loss: 0.0295 - val_accuracy: 0.6667\n",
      "Epoch 18/20\n",
      "1147/1147 [==============================] - 41s 36ms/step - loss: 0.0275 - accuracy: 0.6667 - val_loss: 0.0293 - val_accuracy: 0.6667\n",
      "Epoch 19/20\n",
      "1147/1147 [==============================] - 43s 38ms/step - loss: 0.0275 - accuracy: 0.6667 - val_loss: 0.0291 - val_accuracy: 0.6667\n",
      "Epoch 20/20\n",
      "1147/1147 [==============================] - 44s 38ms/step - loss: 0.0275 - accuracy: 0.6667 - val_loss: 0.0292 - val_accuracy: 0.6667\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 254, 64)           1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 254, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 127, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 127, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 125, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 125, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 60, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 60, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1, 512)            33280     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1, 3)              1539      \n",
      "=================================================================\n",
      "Total params: 61,507\n",
      "Trainable params: 61,123\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "1149/1149 [==============================] - 44s 38ms/step - loss: 0.0819 - accuracy: 0.6634 - val_loss: 0.1042 - val_accuracy: 0.6474\n",
      "Epoch 2/20\n",
      "1149/1149 [==============================] - 42s 37ms/step - loss: 0.0520 - accuracy: 0.6651 - val_loss: 0.0488 - val_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "1149/1149 [==============================] - 40s 35ms/step - loss: 0.0391 - accuracy: 0.6655 - val_loss: 0.0270 - val_accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "1149/1149 [==============================] - 40s 35ms/step - loss: 0.0323 - accuracy: 0.6661 - val_loss: 0.0261 - val_accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "1149/1149 [==============================] - 40s 35ms/step - loss: 0.0323 - accuracy: 0.6661 - val_loss: 0.0271 - val_accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "1149/1149 [==============================] - 40s 35ms/step - loss: 0.0292 - accuracy: 0.6666 - val_loss: 0.0265 - val_accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "1149/1149 [==============================] - 40s 35ms/step - loss: 0.0293 - accuracy: 0.6666 - val_loss: 0.0261 - val_accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "1149/1149 [==============================] - 40s 35ms/step - loss: 0.0290 - accuracy: 0.6666 - val_loss: 0.0259 - val_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "1149/1149 [==============================] - 40s 35ms/step - loss: 0.0290 - accuracy: 0.6666 - val_loss: 0.0259 - val_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "1149/1149 [==============================] - 40s 35ms/step - loss: 0.0287 - accuracy: 0.6667 - val_loss: 0.0274 - val_accuracy: 0.6662\n",
      "Epoch 11/20\n",
      "1149/1149 [==============================] - 40s 35ms/step - loss: 0.0287 - accuracy: 0.6666 - val_loss: 0.0262 - val_accuracy: 0.6667\n",
      "Epoch 12/20\n",
      "1149/1149 [==============================] - 41s 35ms/step - loss: 0.0286 - accuracy: 0.6667 - val_loss: 0.0260 - val_accuracy: 0.6667\n",
      "Epoch 13/20\n",
      "1149/1149 [==============================] - 40s 35ms/step - loss: 0.0285 - accuracy: 0.6667 - val_loss: 0.0260 - val_accuracy: 0.6667\n",
      "Epoch 14/20\n",
      "1149/1149 [==============================] - 40s 35ms/step - loss: 0.0285 - accuracy: 0.6667 - val_loss: 0.0263 - val_accuracy: 0.6667\n",
      "Epoch 15/20\n",
      "1149/1149 [==============================] - 40s 35ms/step - loss: 0.0284 - accuracy: 0.6667 - val_loss: 0.0264 - val_accuracy: 0.6667\n",
      "Epoch 16/20\n",
      "1149/1149 [==============================] - 41s 35ms/step - loss: 0.0284 - accuracy: 0.6667 - val_loss: 0.0263 - val_accuracy: 0.6667\n",
      "Epoch 17/20\n",
      "1149/1149 [==============================] - 40s 35ms/step - loss: 0.0284 - accuracy: 0.6667 - val_loss: 0.0262 - val_accuracy: 0.6667\n",
      "Epoch 18/20\n",
      "1149/1149 [==============================] - 40s 35ms/step - loss: 0.0284 - accuracy: 0.6667 - val_loss: 0.0262 - val_accuracy: 0.6667\n",
      "Epoch 19/20\n",
      "1149/1149 [==============================] - 41s 35ms/step - loss: 0.0284 - accuracy: 0.6667 - val_loss: 0.0264 - val_accuracy: 0.6667\n",
      "Epoch 20/20\n",
      "1149/1149 [==============================] - 40s 35ms/step - loss: 0.0284 - accuracy: 0.6667 - val_loss: 0.0260 - val_accuracy: 0.6667\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 254, 64)           1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 254, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 127, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 127, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 125, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 125, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 60, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 60, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1, 512)            33280     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1, 3)              1539      \n",
      "=================================================================\n",
      "Total params: 61,507\n",
      "Trainable params: 61,123\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1208/1208 [==============================] - 42s 35ms/step - loss: 0.0700 - accuracy: 0.6634 - val_loss: 0.1004 - val_accuracy: 0.6659\n",
      "Epoch 2/20\n",
      "1208/1208 [==============================] - 38s 31ms/step - loss: 0.0463 - accuracy: 0.6650 - val_loss: 0.0458 - val_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "1208/1208 [==============================] - 41s 34ms/step - loss: 0.0342 - accuracy: 0.6659 - val_loss: 0.0327 - val_accuracy: 0.6666\n",
      "Epoch 4/20\n",
      "1208/1208 [==============================] - 42s 35ms/step - loss: 0.0329 - accuracy: 0.6659 - val_loss: 0.0301 - val_accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "1208/1208 [==============================] - 41s 34ms/step - loss: 0.0286 - accuracy: 0.6666 - val_loss: 0.0297 - val_accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "1208/1208 [==============================] - 42s 34ms/step - loss: 0.0286 - accuracy: 0.6666 - val_loss: 0.0294 - val_accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "1208/1208 [==============================] - 41s 34ms/step - loss: 0.0282 - accuracy: 0.6667 - val_loss: 0.0293 - val_accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "1208/1208 [==============================] - 41s 34ms/step - loss: 0.0283 - accuracy: 0.6666 - val_loss: 0.0293 - val_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "1208/1208 [==============================] - 42s 35ms/step - loss: 0.0280 - accuracy: 0.6667 - val_loss: 0.0293 - val_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "1208/1208 [==============================] - 41s 34ms/step - loss: 0.0279 - accuracy: 0.6667 - val_loss: 0.0293 - val_accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "1208/1208 [==============================] - 42s 34ms/step - loss: 0.0278 - accuracy: 0.6667 - val_loss: 0.0292 - val_accuracy: 0.6667\n",
      "Epoch 12/20\n",
      "1208/1208 [==============================] - 41s 34ms/step - loss: 0.0277 - accuracy: 0.6667 - val_loss: 0.0295 - val_accuracy: 0.6667\n",
      "Epoch 13/20\n",
      "1208/1208 [==============================] - 41s 34ms/step - loss: 0.0277 - accuracy: 0.6667 - val_loss: 0.0292 - val_accuracy: 0.6667\n",
      "Epoch 14/20\n",
      "1208/1208 [==============================] - 42s 35ms/step - loss: 0.0277 - accuracy: 0.6667 - val_loss: 0.0292 - val_accuracy: 0.6667\n",
      "Epoch 15/20\n",
      "1208/1208 [==============================] - 41s 34ms/step - loss: 0.0277 - accuracy: 0.6667 - val_loss: 0.0292 - val_accuracy: 0.6667\n",
      "Epoch 16/20\n",
      "1208/1208 [==============================] - 42s 34ms/step - loss: 0.0276 - accuracy: 0.6667 - val_loss: 0.0300 - val_accuracy: 0.6667\n",
      "Epoch 17/20\n",
      "1208/1208 [==============================] - 41s 34ms/step - loss: 0.0276 - accuracy: 0.6667 - val_loss: 0.0293 - val_accuracy: 0.6667\n",
      "Epoch 18/20\n",
      "1208/1208 [==============================] - 41s 34ms/step - loss: 0.0276 - accuracy: 0.6667 - val_loss: 0.0295 - val_accuracy: 0.6667\n",
      "Epoch 19/20\n",
      "1208/1208 [==============================] - 42s 34ms/step - loss: 0.0276 - accuracy: 0.6667 - val_loss: 0.0293 - val_accuracy: 0.6667\n",
      "Epoch 20/20\n",
      "1208/1208 [==============================] - 41s 34ms/step - loss: 0.0276 - accuracy: 0.6667 - val_loss: 0.0292 - val_accuracy: 0.6667\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 254, 64)           1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 254, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 127, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 127, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 125, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 125, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 60, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 60, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1, 512)            33280     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1, 3)              1539      \n",
      "=================================================================\n",
      "Total params: 61,507\n",
      "Trainable params: 61,123\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "1206/1206 [==============================] - 42s 35ms/step - loss: 0.0707 - accuracy: 0.6645 - val_loss: 0.0973 - val_accuracy: 0.6306\n",
      "Epoch 2/20\n",
      "1206/1206 [==============================] - 41s 34ms/step - loss: 0.0463 - accuracy: 0.6655 - val_loss: 0.0352 - val_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "1206/1206 [==============================] - 41s 34ms/step - loss: 0.0361 - accuracy: 0.6657 - val_loss: 0.0362 - val_accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "1206/1206 [==============================] - 42s 34ms/step - loss: 0.0326 - accuracy: 0.6662 - val_loss: 0.0286 - val_accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "1206/1206 [==============================] - 41s 34ms/step - loss: 0.0287 - accuracy: 0.6666 - val_loss: 0.0276 - val_accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "1206/1206 [==============================] - 41s 34ms/step - loss: 0.0291 - accuracy: 0.6666 - val_loss: 0.0284 - val_accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "1206/1206 [==============================] - 41s 34ms/step - loss: 0.0288 - accuracy: 0.6666 - val_loss: 0.0281 - val_accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "1206/1206 [==============================] - 41s 34ms/step - loss: 0.0288 - accuracy: 0.6666 - val_loss: 0.0279 - val_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "1206/1206 [==============================] - 42s 35ms/step - loss: 0.0282 - accuracy: 0.6667 - val_loss: 0.0275 - val_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "1206/1206 [==============================] - 41s 34ms/step - loss: 0.0282 - accuracy: 0.6667 - val_loss: 0.0277 - val_accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "1206/1206 [==============================] - 41s 34ms/step - loss: 0.0281 - accuracy: 0.6667 - val_loss: 0.0275 - val_accuracy: 0.6667\n",
      "Epoch 12/20\n",
      "1206/1206 [==============================] - 41s 34ms/step - loss: 0.0281 - accuracy: 0.6667 - val_loss: 0.0278 - val_accuracy: 0.6667\n",
      "Epoch 13/20\n",
      "1206/1206 [==============================] - 41s 34ms/step - loss: 0.0281 - accuracy: 0.6667 - val_loss: 0.0275 - val_accuracy: 0.6667\n",
      "Epoch 14/20\n",
      "1206/1206 [==============================] - 42s 34ms/step - loss: 0.0280 - accuracy: 0.6667 - val_loss: 0.0278 - val_accuracy: 0.6667\n",
      "Epoch 15/20\n",
      "1206/1206 [==============================] - 37s 31ms/step - loss: 0.0279 - accuracy: 0.6667 - val_loss: 0.0276 - val_accuracy: 0.6667\n",
      "Epoch 16/20\n",
      "1206/1206 [==============================] - 42s 34ms/step - loss: 0.0279 - accuracy: 0.6667 - val_loss: 0.0279 - val_accuracy: 0.6667\n",
      "Epoch 17/20\n",
      "1206/1206 [==============================] - 40s 33ms/step - loss: 0.0280 - accuracy: 0.6667 - val_loss: 0.0276 - val_accuracy: 0.6667\n",
      "Epoch 18/20\n",
      "1206/1206 [==============================] - 42s 35ms/step - loss: 0.0279 - accuracy: 0.6667 - val_loss: 0.0277 - val_accuracy: 0.6667\n",
      "Epoch 19/20\n",
      "1206/1206 [==============================] - 41s 34ms/step - loss: 0.0279 - accuracy: 0.6667 - val_loss: 0.0278 - val_accuracy: 0.6667\n",
      "Epoch 20/20\n",
      "1206/1206 [==============================] - 41s 34ms/step - loss: 0.0279 - accuracy: 0.6667 - val_loss: 0.0280 - val_accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "n_folds = 5\n",
    "n_epochs = 20\n",
    "batch_size = 64\n",
    "history = {}\n",
    "mod = {}\n",
    "for fold in range(n_folds):\n",
    "    X_train, y_train = train['X'][fold], train['y'][fold]\n",
    "    X_test,  y_test  =  test['X'][fold],  test['y'][fold]\n",
    "    mod[fold] = cnn_model()\n",
    "    history[fold] = mod[fold].fit(train['X'][fold], train['y'][fold], \n",
    "                                  validation_data=(test['X'][fold], test['y'][fold]), \n",
    "                                  epochs = n_epochs, batch_size = batch_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/596 - 3s - loss: 0.0272 - accuracy: 0.6667\n",
      "649/649 - 3s - loss: 0.0292 - accuracy: 0.6667\n",
      "643/643 - 3s - loss: 0.0260 - accuracy: 0.6667\n",
      "525/525 - 2s - loss: 0.0292 - accuracy: 0.6667\n",
      "530/530 - 2s - loss: 0.0280 - accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "for fold in mod:\n",
    "    test_loss, test_acc = mod[fold].evaluate(test['X'][fold], test['y'][fold], verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc,vacc = [],[]\n",
    "for fold in history:\n",
    "    acc.append(history[fold].history['accuracy'])\n",
    "    vacc.append(history[fold].history['val_accuracy'])\n",
    "plt.plot(np.mean(acc, axis=0), label='accuracy', color='green')\n",
    "plt.plot(np.mean(vacc, axis=0), label = 'val_accuracy', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss,vloss = [],[]\n",
    "for fold in history:\n",
    "    loss.append(history[fold].history['loss'])\n",
    "    vloss.append(history[fold].history['val_loss'])\n",
    "    \n",
    "plt.plot(np.mean(loss, axis=0), label='Train', color='green')\n",
    "plt.plot(np.mean(vloss, axis=0), label='Validation', color='red')\n",
    "plt.xlabel('Epoch', size=16)\n",
    "plt.ylabel('Loss', size=16)\n",
    "plt.ylim([0., 0.1])\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.keys()\n",
    "a = np.array([[[1,2,3]],[[4,5,6]]])\n",
    "print(a.shape)\n",
    "a.reshape((2,3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19064, 3) (19064,) (19064,)\n",
      "(20742, 3) (20742,) (20742,)\n",
      "(20555, 3) (20555,) (20555,)\n",
      "(16793, 3) (16793,) (16793,)\n",
      "(16935, 3) (16935,) (16935,)\n",
      "\n",
      "Overall\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     no fall       0.98      1.00      0.99     92149\n",
      "    pre-fall       0.00      0.00      0.00      1084\n",
      "        fall       0.00      0.00      0.00       856\n",
      "\n",
      "    accuracy                           0.98     94089\n",
      "   macro avg       0.33      0.33      0.33     94089\n",
      "weighted avg       0.96      0.98      0.97     94089\n",
      "\n",
      "[[92149     0     0]\n",
      " [ 1084     0     0]\n",
      " [  856     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apatch/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# X_train, y_train = train['X'][fold], train['y'][fold]\n",
    "# X_test,  y_test  =  test['X'][fold],  test['y'][fold]\n",
    "ypm, ytm = [], []\n",
    "for fold in mod:\n",
    "    y_pred = mod[fold].predict(test['X'][fold])\n",
    "    y_pred = y_pred.reshape((y_pred.shape[0],y_pred.shape[-1]))\n",
    "    y_pred_max = np.argmax(y_pred, axis=1)\n",
    "    y_test_max = np.argmax(test['y'][fold], axis=1)\n",
    "    if len(ypm) == 0:\n",
    "        ypm = y_pred_max\n",
    "        ytm = y_test_max\n",
    "    else:\n",
    "        ypm = np.concatenate((ypm,y_pred_max))\n",
    "        ytm = np.concatenate((ytm,y_test_max))\n",
    "    print(y_pred.shape, y_pred_max.shape, y_test_max.shape)\n",
    "#     print(classification_report(y_test_max, y_pred_max, target_names=['no fall', 'pre-fall', 'fall']))\n",
    "#     print(confusion_matrix(y_test_max, y_pred_max))\n",
    "#    confusion_matrix(y_test_max, y_pred_max)\n",
    "#     print(classification_report(y_test_max, y_pred_max, target_names=['no fall', 'pre-fall', 'fall']))\n",
    "print(\"\\nOverall\\n\")\n",
    "print(classification_report(ytm, ypm, target_names=['no fall', 'pre-fall', 'fall']))\n",
    "print(confusion_matrix(ytm, ypm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for classification\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Sensitivity} &= \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} \\\\\n",
    "\\text{Specificity} &= \\frac{\\text{TN}}{\\text{TN} + \\text{FP}} \\\\\n",
    "\\text{Accuracy} &= \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{FP} + \\text{TN} + \\text{FN}} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truth_test(_test,_pred, i):\n",
    "    _test = np.array(_test)\n",
    "    _pred = np.array(_pred)\n",
    "    \n",
    "    _pred_pos = _test[_pred == i]\n",
    "    _pred_neg = _test[_pred != i]\n",
    "    \n",
    "    _true_pos = len(_pred_pos[_pred_pos == i])\n",
    "    _fals_pos = len(_pred_pos[_pred_pos != i])\n",
    "    \n",
    "    _true_neg = len(_pred_neg[_pred_neg != i])\n",
    "    _fals_neg = len(_pred_neg[_pred_neg == i])\n",
    "    \n",
    "    return _true_pos, _fals_pos, _true_neg, _fals_neg\n",
    "\n",
    "def sensitivity(_test,_pred, i):\n",
    "    tp, fp, tn, fn = truth_test(_test, _pred, i)\n",
    "    return tp / ( tp + fn)\n",
    "\n",
    "def specificity(_test,_pred, i):\n",
    "    tp, fp, tn, fn = truth_test(_test, _pred, i)\n",
    "    return tn / ( tn + fp)\n",
    "\n",
    "def accuracy(_test, _pred, i):\n",
    "    tp, fp, tn, fn = truth_test(_test, _pred, i)\n",
    "    return (tp+tn) / (tp + fp + tn + fn)\n",
    "\n",
    "for i in range(3):\n",
    "    print(\" Label\", i)\n",
    "    print(\"    accuracy\\t%5.3f\"%accuracy(y_test_max, y_pred_max, i))\n",
    "    print(\" specificity\\t%5.3f\"%specificity(y_test_max, y_pred_max, i))\n",
    "    print(\" sensitivity\\t%5.3f\"%sensitivity(y_test_max, y_pred_max, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "import h5py\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_cnn_200.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_cnn_200.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow([[20047,    72,    50],\n",
    "            [  150,    48,     4],\n",
    "            [   47,     1,   136]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
