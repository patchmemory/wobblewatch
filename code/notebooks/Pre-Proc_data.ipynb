{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# this is for loading the data\n",
    "def load_fall_X(file_name):\n",
    "    temp = np.memmap(file_name, dtype='float32', mode='r')\n",
    "    X = np.reshape(temp, [-1, 256, 6])\n",
    "    return X\n",
    "\n",
    "# this is for loading the labels (one-hot encoding: [1, 0, 0]-->nonfall, [0, 1, 0]-->pre-impact fall, [0, 0, 1]-->fall\t\n",
    "def load_fall_y(file_name):\n",
    "    temp = np.memmap(file_name, dtype='int8', mode='r')\n",
    "    y= np.reshape(temp, [-1, 3])\n",
    "    return y\n",
    "\n",
    "def dset_fpath(fname):\n",
    "    return os.path.abspath(\"data/pre-processed_dataset/%s\" % fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  = {'X': {}, 'y': {}}\n",
    "train = {'X': {}, 'y': {}}\n",
    "for i in range(5):\n",
    "    test['X'][i] = load_fall_X(dset_fpath(\"test_x_%i\" % i))\n",
    "    test['y'][i] = load_fall_y(dset_fpath(\"test_y_%i\" % i))\n",
    "    train['X'][i] = load_fall_X(dset_fpath(\"train_x_%i\" % i))\n",
    "    train['y'][i] = load_fall_y(dset_fpath(\"train_y_%i\" % i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 0\n",
      " X train shape: (75025, 256, 6)\n",
      " y train shape: (75025, 3)\n",
      " X test shape:  (19064, 256, 6)\n",
      " y test shape:  (19064, 3)\n",
      "Set 1\n",
      " X train shape: (73347, 256, 6)\n",
      " y train shape: (73347, 3)\n",
      " X test shape:  (20742, 256, 6)\n",
      " y test shape:  (20742, 3)\n",
      "Set 2\n",
      " X train shape: (73534, 256, 6)\n",
      " y train shape: (73534, 3)\n",
      " X test shape:  (20555, 256, 6)\n",
      " y test shape:  (20555, 3)\n",
      "Set 3\n",
      " X train shape: (77296, 256, 6)\n",
      " y train shape: (77296, 3)\n",
      " X test shape:  (16793, 256, 6)\n",
      " y test shape:  (16793, 3)\n",
      "Set 4\n",
      " X train shape: (77154, 256, 6)\n",
      " y train shape: (77154, 3)\n",
      " X test shape:  (16935, 256, 6)\n",
      " y test shape:  (16935, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Set\", i)\n",
    "    print(\" X train shape:\", train['X'][i].shape)\n",
    "    print(\" y train shape:\", train['y'][i].shape)\n",
    "    print(\" X test shape: \", test['X'][i].shape)\n",
    "    print(\" y test shape: \", test['y'][i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 254, 64)           1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 254, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 127, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 125, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 125, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 60, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 60, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 512)               983552    \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 1,011,779\n",
      "Trainable params: 1,011,395\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_timesteps = 256\n",
    "n_features = 6\n",
    "n_outputs = 3\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# First layer\n",
    "model.add(layers.Conv1D(kernel_size=3, \n",
    "                        filters=64, \n",
    "                        activation='relu', \n",
    "                        input_shape=(n_timesteps, n_features)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "# Second layer\n",
    "model.add(layers.Conv1D(kernel_size = 3, \n",
    "                        filters = 64, \n",
    "                        activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "\n",
    "# Third layer\n",
    "model.add(layers.Conv1D(kernel_size = 3, \n",
    "                        filters = 64, \n",
    "                        activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512))\n",
    "model.add(layers.Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "print(model.summary())\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1173/1173 [==============================] - 30s 26ms/step - loss: 0.1969 - accuracy: 0.9682\n",
      "Epoch 2/30\n",
      "1173/1173 [==============================] - 30s 25ms/step - loss: 0.0697 - accuracy: 0.9820\n",
      "Epoch 3/30\n",
      "1173/1173 [==============================] - 29s 25ms/step - loss: 0.0611 - accuracy: 0.9829\n",
      "Epoch 4/30\n",
      "1173/1173 [==============================] - 29s 24ms/step - loss: 0.0591 - accuracy: 0.9827\n",
      "Epoch 5/30\n",
      "1173/1173 [==============================] - 29s 24ms/step - loss: 0.0533 - accuracy: 0.9841\n",
      "Epoch 6/30\n",
      "1173/1173 [==============================] - 29s 25ms/step - loss: 0.0503 - accuracy: 0.9845\n",
      "Epoch 7/30\n",
      "1173/1173 [==============================] - 29s 25ms/step - loss: 0.0457 - accuracy: 0.9858\n",
      "Epoch 8/30\n",
      "1173/1173 [==============================] - 28s 24ms/step - loss: 0.0426 - accuracy: 0.9868\n",
      "Epoch 9/30\n",
      "1173/1173 [==============================] - 28s 24ms/step - loss: 0.0399 - accuracy: 0.9872\n",
      "Epoch 10/30\n",
      "1173/1173 [==============================] - 29s 24ms/step - loss: 0.0372 - accuracy: 0.9878\n",
      "Epoch 11/30\n",
      "1173/1173 [==============================] - 29s 24ms/step - loss: 0.0356 - accuracy: 0.9888\n",
      "Epoch 12/30\n",
      "1173/1173 [==============================] - 29s 24ms/step - loss: 0.0334 - accuracy: 0.9893\n",
      "Epoch 13/30\n",
      "1173/1173 [==============================] - 29s 24ms/step - loss: 0.0324 - accuracy: 0.9894\n",
      "Epoch 14/30\n",
      "1173/1173 [==============================] - 29s 24ms/step - loss: 0.0284 - accuracy: 0.9905\n",
      "Epoch 15/30\n",
      "1173/1173 [==============================] - 29s 25ms/step - loss: 0.0288 - accuracy: 0.9904\n",
      "Epoch 16/30\n",
      "1173/1173 [==============================] - 29s 24ms/step - loss: 0.0277 - accuracy: 0.9909\n",
      "Epoch 17/30\n",
      "1173/1173 [==============================] - 29s 24ms/step - loss: 0.0258 - accuracy: 0.9917\n",
      "Epoch 18/30\n",
      "1173/1173 [==============================] - 29s 24ms/step - loss: 0.0248 - accuracy: 0.9921\n",
      "Epoch 19/30\n",
      "1173/1173 [==============================] - 28s 24ms/step - loss: 0.0241 - accuracy: 0.9920\n",
      "Epoch 20/30\n",
      "1173/1173 [==============================] - 28s 24ms/step - loss: 0.0229 - accuracy: 0.9928\n",
      "Epoch 21/30\n",
      "1173/1173 [==============================] - 28s 24ms/step - loss: 0.0222 - accuracy: 0.9930\n",
      "Epoch 22/30\n",
      "1173/1173 [==============================] - 29s 24ms/step - loss: 0.0201 - accuracy: 0.9933\n",
      "Epoch 23/30\n",
      "1173/1173 [==============================] - 29s 24ms/step - loss: 0.0214 - accuracy: 0.9930\n",
      "Epoch 24/30\n",
      "1173/1173 [==============================] - 29s 24ms/step - loss: 0.0177 - accuracy: 0.9943\n",
      "Epoch 25/30\n",
      "1173/1173 [==============================] - 29s 24ms/step - loss: 0.0191 - accuracy: 0.9937\n",
      "Epoch 26/30\n",
      "1173/1173 [==============================] - 30s 25ms/step - loss: 0.0187 - accuracy: 0.9939\n",
      "Epoch 27/30\n",
      "1173/1173 [==============================] - 40s 34ms/step - loss: 0.0185 - accuracy: 0.9941\n",
      "Epoch 28/30\n",
      "1173/1173 [==============================] - 44s 38ms/step - loss: 0.0161 - accuracy: 0.9949\n",
      "Epoch 29/30\n",
      "1173/1173 [==============================] - 45s 38ms/step - loss: 0.0161 - accuracy: 0.9946\n",
      "Epoch 30/30\n",
      "1173/1173 [==============================] - 45s 39ms/step - loss: 0.0158 - accuracy: 0.9947\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "X_train, y_train = train['X'][i], train['y'][i]\n",
    "X_test, y_test = test['X'][i], test['y'][i]\n",
    "history = model.fit(X_train, y_train, epochs = 30, batch_size = 64 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/596 - 3s - loss: 0.1653 - accuracy: 0.9838\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-eaeb40ec4f7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9999976e-01, 1.8367679e-07, 1.9128464e-10],\n",
       "       [9.9995530e-01, 3.7284877e-08, 4.4650358e-05],\n",
       "       [9.9999988e-01, 1.7493066e-07, 4.3041200e-13],\n",
       "       ...,\n",
       "       [9.9999559e-01, 4.4324811e-06, 1.7954287e-09],\n",
       "       [9.9999845e-01, 1.4911587e-06, 1.3082690e-09],\n",
       "       [9.9998975e-01, 1.0211564e-05, 9.7351716e-10]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_max = np.argmax(y_pred, axis=1)\n",
    "y_test_max = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18598,    54,    29],\n",
       "       [  174,    58,     1],\n",
       "       [   46,     5,    99]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "confusion_matrix(y_test_max, y_pred_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     no fall       0.99      1.00      0.99     18681\n",
      "    pre-fall       0.50      0.25      0.33       233\n",
      "        fall       0.77      0.66      0.71       150\n",
      "\n",
      "    accuracy                           0.98     19064\n",
      "   macro avg       0.75      0.63      0.68     19064\n",
      "weighted avg       0.98      0.98      0.98     19064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_max, y_pred_max, target_names=['no fall', 'pre-fall', 'fall']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics\n",
    "\\begin{align}\n",
    "\\text{Sensitivity} &= \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} \\\\\n",
    "\\text{Specificity} &= \\frac{\\text{TN}}{\\text{TN} + \\text{FP}} \\\\\n",
    "\\text{Accuracy} &= \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{FP} + \\text{TN} + \\text{FN}} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truth_test(_test,_pred, i):\n",
    "    _test = np.array(_test)\n",
    "    _pred = np.array(_pred)\n",
    "    \n",
    "    _pred_pos = _test[_pred == i]\n",
    "    _pred_neg = _test[_pred != i]\n",
    "    \n",
    "    _true_pos = len(_pred_pos[_pred_pos == i])\n",
    "    _fals_pos = len(_pred_pos[_pred_pos != i])\n",
    "    \n",
    "    _true_neg = len(_pred_neg[_pred_neg != i])\n",
    "    _fals_neg = len(_pred_neg[_pred_neg == i])\n",
    "    \n",
    "    return _true_pos, _fals_pos, _true_neg, _fals_neg\n",
    "\n",
    "def sensitivity(_test,_pred, i):\n",
    "    tp, fp, tn, fn = truth_test(_test, _pred, i)\n",
    "    return tp / ( tp + fn)\n",
    "\n",
    "def specificity(_test,_pred, i):\n",
    "    tp, fp, tn, fn = truth_test(_test, _pred, i)\n",
    "    return tn / ( tn + fp)\n",
    "\n",
    "def accuracy(_test, _pred, i):\n",
    "    tp, fp, tn, fn = truth_test(_test, _pred, i)\n",
    "    return (tp+tn) / (tp + fp + tn + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Label 0\n",
      "    accuracy\t0.984\n",
      " specificity\t0.426\n",
      " sensitivity\t0.996\n",
      " Label 1\n",
      "    accuracy\t0.988\n",
      " specificity\t0.997\n",
      " sensitivity\t0.249\n",
      " Label 2\n",
      "    accuracy\t0.996\n",
      " specificity\t0.998\n",
      " sensitivity\t0.660\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\" Label\", i)\n",
    "    print(\"    accuracy\\t%5.3f\"%accuracy(y_test_max, y_pred_max, i))\n",
    "    print(\" specificity\\t%5.3f\"%specificity(y_test_max, y_pred_max, i))\n",
    "    print(\" sensitivity\\t%5.3f\"%sensitivity(y_test_max, y_pred_max, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now for the hybrid model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 254, 64)           1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 254, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 127, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 125, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 125, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 60, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 60, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 512)               983552    \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 1,011,779\n",
      "Trainable params: 1,011,395\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_timesteps = 256\n",
    "n_features = 6\n",
    "n_outputs = 3\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# First layer\n",
    "model.add(layers.Conv1D(kernel_size=3, \n",
    "                        filters=64, \n",
    "                        activation='relu', \n",
    "                        input_shape=(n_timesteps, n_features)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "# Second layer\n",
    "model.add(layers.Conv1D(kernel_size = 3, \n",
    "                        filters = 64, \n",
    "                        activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "\n",
    "# Third layer\n",
    "model.add(layers.Conv1D(kernel_size = 3, \n",
    "                        filters = 64, \n",
    "                        activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512))\n",
    "model.add(layers.Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/apatch/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: cnn_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"cnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
